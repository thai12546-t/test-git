{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Họ và tên : Trần Anh Thái\n",
    "## MSSV : 22H1320007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tạo dataframe \n",
    "import pandas as pd\n",
    "\n",
    "with open('SMSSpamCollection', 'r', encoding='UTF-8') as file:\n",
    "    email_data = file.read()\n",
    "    \n",
    "lines = email_data.strip().split(\"\\n\")\n",
    "data = [line.split(\"\\t\", 1) for line in lines]\n",
    "df = pd.DataFrame(data, columns=[\"label\", \"content\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading puntk_tab: Package 'puntk_tab' not found in\n",
      "[nltk_data]     index\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('puntk_tab')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords.words('english')] \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point, crazy.. available bugis n gre...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3               u dun say early hor... u c already say...\n",
       "4                 nah think goes usf, lives around though\n",
       "                              ...                        \n",
       "5569    2nd time tried 2 contact u. u £750 pound prize...\n",
       "5570                         ü b going esplanade fr home?\n",
       "5571             pity, * mood that. so...any suggestions?\n",
       "5572    guy bitching acted like i'd interested buying ...\n",
       "5573                                      rofl. true name\n",
       "Name: message, Length: 5574, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3901,) (1673,)\n"
     ]
    }
   ],
   "source": [
    "#Phân chia tập train, test theo tỉ lệ 7:3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector hóa dữ liệu text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#Khởi tạo CountVectorizer\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "X_train_Count = count_vector.fit_transform(X_train).toarray()\n",
    "X_test_Count = count_vector.transform(X_test).toarray()\n",
    "\n",
    "#Khởi tạo TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "names = ['Support Vector Machines (SVM)',\n",
    "         'Logistic Regression',\n",
    "         'Naive Bayes']\n",
    "\n",
    "classifier = [\n",
    "    SVC(kernel = 'rbf'),\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector hóa dữ liệu text dùng CountVectorizer\n",
      "Score of Support Vector Machines (SVM) : 0.9760908547519426\n",
      "Score of Logistic Regression : 0.9760908547519426\n",
      "Score of Naive Bayes : 0.9838613269575612\n",
      "\n",
      "Vector hóa dữ liệu text dùng TfidfVectorizer\n",
      "Score of Support Vector Machines (SVM) : 0.9772863120143455\n",
      "Score of Logistic Regression : 0.9557680812910938\n",
      "Score of Naive Bayes : 0.9641362821279139\n"
     ]
    }
   ],
   "source": [
    "print('Vector hóa dữ liệu text dùng CountVectorizer')\n",
    "for name, clf in zip(names, classifier):\n",
    "    print(f'Score of {name} : {clf.fit(X_train_Count, y_train).score(X_test_Count, y_test)}')\n",
    "\n",
    "print('\\nVector hóa dữ liệu text dùng TfidfVectorizer')\n",
    "for name, clf in zip(names, classifier):\n",
    "    print(f'Score of {name} : {clf.fit(X_train_tfidf, y_train).score(X_test_tfidf, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_use_CountVectorizer(message, names, classifier):\n",
    "    message_vector = count_vector.transform([message]).toarray()\n",
    "    for name, clf in zip(names, classifier):\n",
    "        print(f'Prediction of {name} : {clf.predict(message_vector)}')\n",
    "        \n",
    "def test_model_use_TfidfVectorizer(message, names, classifier):\n",
    "    message_vector = tfidf_vectorizer.transform([message]).toarray()\n",
    "    for name, clf in zip(names, classifier):\n",
    "        print(f'Prediction of {name} : {clf.predict(message_vector)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nội dung email : \n",
      "No. I meant the calculation is the same. That  &lt;#&gt; units at  &lt;#&gt; . This school is really expensive. Have you started practicing your accent. Because its important. And have you decided if you are doing 4years of dental school or if you'll just do the nmde exam.\n",
      "Vector hóa dữ liệu text dùng CountVectorizer\n",
      "Prediction of Support Vector Machines (SVM) : ['ham']\n",
      "Prediction of Logistic Regression : ['ham']\n",
      "Prediction of Naive Bayes : ['ham']\n",
      "\n",
      "Vector hóa dữ liệu text dùng TfidfVectorizer\n",
      "Prediction of Support Vector Machines (SVM) : ['ham']\n",
      "Prediction of Logistic Regression : ['ham']\n",
      "Prediction of Naive Bayes : ['ham']\n"
     ]
    }
   ],
   "source": [
    "email_input = input(\"Nhập nội dung email để dự đoán: \\n\")\n",
    "print('Nội dung email : ')\n",
    "print(email_input)\n",
    "\n",
    "print(f'Vector hóa dữ liệu text dùng CountVectorizer')\n",
    "try:\n",
    "    test_model_use_CountVectorizer(email_input, names, classifier)\n",
    "\n",
    "    print('\\nVector hóa dữ liệu text dùng TfidfVectorizer')\n",
    "    test_model_use_TfidfVectorizer(email_input, names, classifier)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
